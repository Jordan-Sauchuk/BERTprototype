{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Setup.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ojiO8uRalQR5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install keras-bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sEDEI80MlTMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "35e9a1d0-9095-4a79-a055-91c2b570f3d7"
      },
      "cell_type": "code",
      "source": [
        "from keras_bert import Tokenizer\n",
        "\n",
        "token_dict = {\n",
        "    '[CLS]': 0,\n",
        "    '[SEP]': 1,\n",
        "    'un': 2,\n",
        "    '##aff': 3,\n",
        "    '##able': 4,\n",
        "    '[UNK]': 5,\n",
        "}\n",
        "tokenizer = Tokenizer(token_dict)\n",
        "print(tokenizer.tokenize('unaffable'))  # The result should be `['[CLS]', 'un', '##aff', '##able', '[SEP]']`\n",
        "indices, segments = tokenizer.encode('unaffable')\n",
        "print(indices)  # Should be `[0, 2, 3, 4, 1]`\n",
        "print(segments)  # Should be `[0, 0, 0, 0, 0]`\n",
        "\n",
        "print(tokenizer.tokenize(first='unaffable', second='钢'))\n",
        "# The result should be `['[CLS]', 'un', '##aff', '##able', '[SEP]', '钢', '[SEP]']`\n",
        "indices, segments = tokenizer.encode(first='unaffable', second='钢', max_len=10)\n",
        "print(indices)  # Should be `[0, 2, 3, 4, 1, 5, 1, 0, 0, 0]`\n",
        "print(segments)  # Should be `[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]`"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'un', '##aff', '##able', '[SEP]']\n",
            "[0, 2, 3, 4, 1]\n",
            "[0, 0, 0, 0, 0]\n",
            "['[CLS]', 'un', '##aff', '##able', '[SEP]', '钢', '[SEP]']\n",
            "[0, 2, 3, 4, 1, 5, 1, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5qwKGuFgldCr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras_bert import get_base_dict, get_model, gen_batch_inputs\n",
        "\n",
        "\n",
        "# A toy input example\n",
        "sentence_pairs = [\n",
        "    [['all', 'work', 'and', 'no', 'play'], ['makes', 'jack', 'a', 'dull', 'boy']],\n",
        "    [['from', 'the', 'day', 'forth'], ['my', 'arm', 'changed']],\n",
        "    [['and', 'a', 'voice', 'echoed'], ['power', 'give', 'me', 'more', 'power']],\n",
        "]\n",
        "\n",
        "\n",
        "# Build token dictionary\n",
        "token_dict = get_base_dict()  # A dict that contains some special tokens\n",
        "for pairs in sentence_pairs:\n",
        "    for token in pairs[0] + pairs[1]:\n",
        "        if token not in token_dict:\n",
        "            token_dict[token] = len(token_dict)\n",
        "token_list = list(token_dict.keys())  # Used for selecting a random word\n",
        "\n",
        "\n",
        "# Build & train the model\n",
        "model = get_model(\n",
        "    token_num=len(token_dict),\n",
        "    head_num=5,\n",
        "    transformer_num=12,\n",
        "    embed_dim=25,\n",
        "    feed_forward_dim=100,\n",
        "    seq_len=20,\n",
        "    pos_num=20,\n",
        "    dropout_rate=0.05,\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "def _generator():\n",
        "    while True:\n",
        "        yield gen_batch_inputs(\n",
        "            sentence_pairs,\n",
        "            token_dict,\n",
        "            token_list,\n",
        "            seq_len=20,\n",
        "            mask_rate=0.3,\n",
        "            swap_sentence_rate=1.0,\n",
        "        )\n",
        "\n",
        "model.fit_generator(\n",
        "    generator=_generator(),\n",
        "    steps_per_epoch=1000,\n",
        "    epochs=100,\n",
        "    validation_data=_generator(),\n",
        "    validation_steps=100,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "    ],\n",
        ")\n",
        "\n",
        "\n",
        "# Use the trained model\n",
        "inputs, output_layer = get_model(  # `output_layer` is the last feature extraction layer (the last transformer)\n",
        "    token_num=len(token_dict),\n",
        "    head_num=5,\n",
        "    transformer_num=12,\n",
        "    embed_dim=25,\n",
        "    feed_forward_dim=100,\n",
        "    seq_len=20,\n",
        "    pos_num=20,\n",
        "    dropout_rate=0.05,\n",
        "    training=False,   # The input layers and output layer will be returned if `training` is `False`\n",
        "    trainable=False,  # Whether the model is trainable. The default value is the same with `training`\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DY0l7NtYlspO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras as keras\n",
        "def _custom_layers(x, trainable=True):\n",
        "    return keras.layers.LSTM(\n",
        "        units=768,\n",
        "        trainable=trainable,\n",
        "        return_sequences=True,\n",
        "        name='LSTM',\n",
        "    )(x)\n",
        "\n",
        "model = get_model(\n",
        "    token_num=200,\n",
        "    embed_dim=768,\n",
        "    custom_layers=_custom_layers,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8XtW9ofumoBz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6S_kPEnIlxQF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "2637bdd7-da46-4491-eb34-4bb7b37e5157"
      },
      "cell_type": "code",
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "\n",
        "# Hello! Does this work with German sentences, too?\n",
        "text = 'Ik snap het niet (informeel)'\n",
        "text_one = 'Ik weet het niet meer'\n",
        "text_two = 'Het is duidelijk'\n",
        "text_three = 'Ik weet niet hoe je dat zegt in het NL'\n",
        "text_four = \"TMG websites en apps maken gebruik van cookies en vergelijkbare technieken i) voor functionele en analytische doeleinden, ii) om het mogelijk te maken content via social media te delen, iii) om informatie te verzamelen over uw voorkeuren en de informatie toe te voegen aan uw klantprofiel en iv) om de inhoud van haar websites en advertenties af te stemmen op uw voorkeuren. Cookies kunnen ook geplaatst en gebruikt worden door derden, zoals advertentienetwerken, adverteerders en technologiepartners. Meer informatie over het cookiegebruik op de TMG websites en apps, waaronder de specifieke cookies, doeleinden en bewaartermijnen vindt u hier. TMG deelt de informatie die zij verkrijgt middels het gebruik van cookies en vergelijkbare technieken, waaronder ook persoonsgegevens,  in een samenwerkingsverband genaamd NLProfiel van Buymedia Nederland met Sanoma en de Persgroep, om gezamenlijke groepsprofielen op te stellen. Ook gaat u dan akkoord met de verwerking van de (persoons)gegevens die met behulp van cookies door TMG en derden kunnen worden verzameld en verwerkt voor de onder i) tot en met iv) genoemde doeleinden, alsmede met de verstrekking van uw (persoons)gegevens aan Sanoma en de Persgroep voor de totstandkoming van de gezamenlijke groepsprofielen. Meer informatie over deze verwerking van (persoons)gegevens kunt u vinden in de privacyverklaring van TMG respectievelijk van deze derden.\"\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_text = tokenizer.tokenize(text)\n",
        "tokenized_text_one = tokenizer.tokenize(text_one)\n",
        "tokenized_text_two = tokenizer.tokenize(text_two)\n",
        "tokenized_text_three = tokenizer.tokenize(text_three)\n",
        "tokenized_text_four = tokenizer.tokenize(text_four)\n",
        "\n",
        "\n",
        "print(tokenized_text)\n",
        "print(tokenized_text_one)\n",
        "print(tokenized_text_two)\n",
        "print(tokenized_text_three)\n",
        "print(tokenized_text_four)\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 995526/995526 [00:00<00:00, 12554008.90B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['Ik', 'sna', '##p', 'het', 'niet', '(', 'informe', '##el', ')']\n",
            "['Ik', 'weet', 'het', 'niet', 'meer']\n",
            "['Het', 'is', 'duidelijk']\n",
            "['Ik', 'weet', 'niet', 'hoe', 'je', 'dat', 'ze', '##gt', 'in', 'het', 'NL']\n",
            "['TM', '##G', 'websites', 'en', 'app', '##s', 'maken', 'gebruik', 'van', 'co', '##okie', '##s', 'en', 'ver', '##gelijk', '##bare', 'tech', '##niek', '##en', 'i', ')', 'voor', 'function', '##ele', 'en', 'anal', '##yti', '##sche', 'doel', '##ein', '##den', ',', 'ii', ')', 'om', 'het', 'mogelijk', 'te', 'maken', 'content', 'via', 'social', 'media', 'te', 'delen', ',', 'iii', ')', 'om', 'informatie', 'te', 'ver', '##zame', '##len', 'over', 'u', '##w', 'voor', '##keur', '##en', 'en', 'de', 'informatie', 'toe', 'te', 'voe', '##gen', 'aan', 'u', '##w', 'kl', '##ant', '##pro', '##fiel', 'en', 'i', '##v', ')', 'om', 'de', 'in', '##houd', 'van', 'haar', 'websites', 'en', 'ad', '##verte', '##nties', 'af', 'te', 'stemmen', 'op', 'u', '##w', 'voor', '##keur', '##en', '.', 'Cook', '##ies', 'kunnen', 'ook', 'geplaatst', 'en', 'gebruikt', 'worden', 'door', 'derde', '##n', ',', 'zoals', 'ad', '##verte', '##ntie', '##net', '##werken', ',', 'ad', '##verte', '##erde', '##rs', 'en', 'technologie', '##part', '##ners', '.', 'Meer', 'informatie', 'over', 'het', 'co', '##okie', '##ge', '##bru', '##ik', 'op', 'de', 'TM', '##G', 'websites', 'en', 'app', '##s', ',', 'waaronder', 'de', 'sp', '##eci', '##fie', '##ke', 'co', '##okie', '##s', ',', 'doel', '##ein', '##den', 'en', 'be', '##waar', '##ter', '##mi', '##jnen', 'vindt', 'u', 'hier', '.', 'TM', '##G', 'deel', '##t', 'de', 'informatie', 'die', 'zij', 'verk', '##rij', '##gt', 'middel', '##s', 'het', 'gebruik', 'van', 'co', '##okie', '##s', 'en', 'ver', '##gelijk', '##bare', 'tech', '##niek', '##en', ',', 'waaronder', 'ook', 'persoon', '##sg', '##ege', '##vens', ',', 'in', 'een', 'samenwerking', '##s', '##verband', 'genaamd', 'NL', '##P', '##ro', '##fiel', 'van', 'Buy', '##media', 'Nederland', 'met', 'San', '##oma', 'en', 'de', 'Pers', '##groep', ',', 'om', 'ge', '##zame', '##nl', '##ijke', 'groep', '##sp', '##ro', '##fiel', '##en', 'op', 'te', 'stellen', '.', 'Ook', 'gaat', 'u', 'dan', 'ak', '##ko', '##ord', 'met', 'de', 'ver', '##werking', 'van', 'de', '(', 'persoon', '##s', ')', 'gegevens', 'die', 'met', 'behulp', 'van', 'co', '##okie', '##s', 'door', 'TM', '##G', 'en', 'derde', '##n', 'kunnen', 'worden', 'ver', '##zame', '##ld', 'en', 'ver', '##werkt', 'voor', 'de', 'onder', 'i', ')', 'tot', 'en', 'met', 'i', '##v', ')', 'genoemd', '##e', 'doel', '##ein', '##den', ',', 'als', '##mede', 'met', 'de', 'vers', '##tre', '##kking', 'van', 'u', '##w', '(', 'persoon', '##s', ')', 'gegevens', 'aan', 'San', '##oma', 'en', 'de', 'Pers', '##groep', 'voor', 'de', 'tots', '##tand', '##kom', '##ing', 'van', 'de', 'ge', '##zame', '##nl', '##ijke', 'groep', '##sp', '##ro', '##fiel', '##en', '.', 'Meer', 'informatie', 'over', 'deze', 'ver', '##werking', 'van', '(', 'persoon', '##s', ')', 'gegevens', 'kun', '##t', 'u', 'vinden', 'in', 'de', 'pri', '##vacy', '##verk', '##lari', '##ng', 'van', 'TM', '##G', 'respect', '##ieve', '##lijk', 'van', 'deze', 'derde', '##n', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EIAjCTWvgpaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f6be39e6-40e2-4d5d-ce9f-9cd16983db7c"
      },
      "cell_type": "code",
      "source": [
        "from pytorch_pretrained_bert import BasicTokenizer, BertTokenizer\n",
        "\n",
        "# Insert example text\n",
        "text = '...'\n",
        "\n",
        "basic_tokenizer = BasicTokenizer(do_lower_case=False)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "\n",
        "in_vocab = []\n",
        "not_in_vocab = []\n",
        "\n",
        "for word in basic_tokenizer.tokenize(text):\n",
        "    if word in tokenizer.vocab:\n",
        "        in_vocab.append(word)\n",
        "    else:\n",
        "        not_in_vocab.append(word)\n",
        "\n",
        "print(len(in_vocab))\n",
        "print(len(not_in_vocab))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "biw5girLmch8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}